{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covid Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1: Reporting number of COVID-19 cases in each London local authority \n",
    "First, read the “cases.csv” dataset into a dataframe. Create a new dataframe where rows are the unique names of London local authorities and the columns are the total number of covid cases in each London local authority (include both count columns in the starting dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cases.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2de0e0e488f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_cases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cases.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_cases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cases.csv'"
     ]
    }
   ],
   "source": [
    "df_cases=pd.read_csv(\"cases.csv\",sep=\",\")\n",
    "df_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: The geographical locations have similar population size for as estimated number for covid_19_deaths_per_thousand column, since population data is from mid 2018 which may vary from the actual 2020 numbers.\n",
    "new_df_cases=df_cases.groupby('Local authority',as_index=False).agg({'covid_19_deaths':'sum','covid_19_deaths_per_thousand':'mean'})\n",
    "new_df_cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Calculating percentage of COVID-19 cases in each London local authority \n",
    "Read the “population.csv” dataset and calculate the percentage of covid cases in each city of London region according to the total population and add it as a new column to the datafame. Sort the dataframe according to this column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population=pd.read_csv('population.csv')\n",
    "df_population.head()\n",
    "\n",
    "# Assumption: The geographical locations have similar population size for as estimated number for the over_70_prop column.\n",
    "\n",
    "new_df_population=df_population.groupby('Local authority',as_index=False).agg({'total_population_mid_2018':'sum','over_70_prop':'mean'})\n",
    "new_df_population.head()\n",
    "new_df_cases=pd.merge(new_df_cases,new_df_population,on='Local authority',how='outer')\n",
    "new_df_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding percentage_of_cases column with unit %\n",
    "new_df_cases['percentage_of_cases(%)']=new_df_cases['covid_19_deaths']/new_df_cases['total_population_mid_2018']*100\n",
    "\n",
    "# Sorted the column in descending order to see Local authorities with the highest percentage of cases\n",
    "new_df_cases=new_df_cases.sort_values('percentage_of_cases(%)',ascending=False)\n",
    "new_df_cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Finding the largest and smallest population based on ethnicity group in each city of London\n",
    "\n",
    "Read the “ethnic.csv” dataset and calculate the population of different ethnicity groups in each London borough using column “total\\_population\\_mid\\_2018” from the first dataset “cases.csv”. Plot a bar chart to compare cases in each ethnicity group for each London local authority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ethnic=pd.read_csv('ethnic.csv',sep=',')\n",
    "# df_ethnic = df_ethnic.rename(columns={'Local Authority': 'Local authority'})\n",
    "\n",
    "ethnicity_by_boroughs=df_ethnic[['all_bame_prop','all_black_prop','pakistani_or_bangladeshi_prop','all_indian_prop']].multiply(df_population['total_population_mid_2018'],axis=0)\n",
    "\n",
    "ethnicity_by_boroughs=ethnicity_by_boroughs.rename(columns={'all_bame_prop':'bame_population','all_black_prop':'black_population','pakistani_or_bangladeshi_prop':'pakistani_bangladeshi_population','all_indian_prop':'indian_population'})\n",
    "ethnicity_by_boroughs.insert(0,'Local Authority',df_ethnic['Local Authority'])\n",
    "ethnicity_by_boroughs=ethnicity_by_boroughs.groupby('Local Authority',as_index=False).sum()\n",
    "\n",
    "# Calculating the population of other minorities within BAME who are not black, pakistani or bangladeshi, or indian.\n",
    "ethnicity_by_boroughs['other_minority_population']=ethnicity_by_boroughs['bame_population']-ethnicity_by_boroughs['black_population']-ethnicity_by_boroughs['pakistani_bangladeshi_population']-ethnicity_by_boroughs['indian_population']\n",
    "ethnicity_by_boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding the white population under the assumption that this chart is just to analyse the population of minority groups in London local authority.\n",
    "# Excluding BAME population column from this chart as the total population plotted, i.e. black, pakistani & bangladeshi, indian and other minorities, add up to the total BAME population.\n",
    "ethnicity_chart=ethnicity_by_boroughs.plot.bar(x='Local Authority',y=['black_population','pakistani_bangladeshi_population','indian_population','other_minority_population'],title='Population of ethnic groups by London local authorities',figsize=(20,10),stacked=True)\n",
    "ethnicity_chart.set_ylabel(\"Population\")\n",
    "# Assuming that the intention of this chart is to understand if there is a disporportionate impact of the virus against minorities, it would be helpful to have the covid cases data by each ethnic group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4: Analysing the medical conditions of each region\n",
    "Read the “medical.csv” dataset. Calculate total percentage of patients with “Hypertension”, “Obesity (18+)”, “Diabetes”, “Asthma”, and “Coronary heart disease” for each London local authority. For each medical condition, draw a boxplot of medical case frequencies for the 5 regions with the highest \"total\\_registered\\_patient\". Then, add a new column to the daraframe from section 1.2 to show the medical conditions with the highest number patients in each London borough.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medical=pd.read_csv('medical.csv',sep=',')\n",
    "# Assuming that the data for each medical conditions is independent from each other.\n",
    "medical_condition_population=df_medical[['Hypertension','Obesity (18+)','Diabetes','Asthma','Coronary heart disease']].multiply(df_medical['total_registered_patients'],axis=0)\n",
    "# Dividing the population by 100 as previous numbers were in percentages and not proportions.\n",
    "medical_condition_population=medical_condition_population/100\n",
    "\n",
    "# Adding the Local Authority and Total registered patients columns for analysis - to groupby Local authority and calculate the percentage of the medical conditions by local authority\n",
    "medical_condition_population.insert(0,'Local authority',df_medical['Local authority'])\n",
    "medical_condition_population.insert(1,'total_registered_patients',df_medical['total_registered_patients'])\n",
    "medical_condition_population=medical_condition_population.groupby('Local authority',as_index=False).sum()\n",
    "# Calculating the total percentages for each medical condition by local authority\n",
    "medical_condition_population['Hypertension']=medical_condition_population['Hypertension']/medical_condition_population['total_registered_patients']*100\n",
    "medical_condition_population['Obesity (18+)']=medical_condition_population['Obesity (18+)']/medical_condition_population['total_registered_patients']*100\n",
    "medical_condition_population['Diabetes']=medical_condition_population['Diabetes']/medical_condition_population['total_registered_patients']*100\n",
    "medical_condition_population['Asthma']=medical_condition_population['Asthma']/medical_condition_population['total_registered_patients']*100\n",
    "medical_condition_population['Coronary heart disease']=medical_condition_population['Coronary heart disease']/medical_condition_population['total_registered_patients']*100\n",
    "\n",
    "# Sorting the data to see regions with the highest number of registered patients\n",
    "medical_condition_population=medical_condition_population.sort_values('total_registered_patients',ascending=False)\n",
    "\n",
    "top_5_regions=medical_condition_population.head()\n",
    "# The 5 regions with the highest Total Registered Patients are Ealing, Croydon, Barnet, Newham and Brent.\n",
    "medical_top_5=top_5_regions.boxplot(column=['Hypertension','Obesity (18+)','Diabetes','Asthma','Coronary heart disease'],figsize=(20,10))\n",
    "medical_top_5.set_xlabel('Medical Conditions')\n",
    "medical_top_5.set_ylabel('Percentage of registered patients (%)')\n",
    "plt.title('Medical cases for the 5 regions with the highest number of registered patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: Adding column to show the most common medical condition within each local authority, i.e. stating which medical condition has the highest number of patients.\n",
    "# Finding the most common medical condition by local authority.\n",
    "medical_condition_population['Most common medical condition'] = medical_condition_population[['Hypertension','Obesity (18+)','Diabetes','Asthma','Coronary heart disease']].idxmax(axis=1)\n",
    "new_df_cases = pd.merge(new_df_cases,medical_condition_population[['Local authority','Most common medical condition']],on='Local authority', how='left')\n",
    "new_df_cases.head()\n",
    "# As seen in the boxplot, and further confirmed by the newly added column, Hypertension is the most common medical condition for all local authorities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1: Reading in the datasets\n",
    "Read columns \"country, date, cases\" from file \"confirmed\\_cases\\_by\\_country.csv\" into a dataframe called \"cases\\_by\\_country\".\n",
    "Read columns \"is\\_china, date, cases\" from \"confirmed\\_cases\\_china\\_vs\\_world.csv\" into a dataframe called \"cases\\_all\". Rename the column \"is\\_china\" to \"country\" (hint you may use .rename()). Then split this dataframe into two new ones: cases in China (\"cases\\_china\") and cases elsewhere (\"cases\\_not\\_china\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_by_country=pd.read_csv(\"confirmed_cases_by_country.csv\",usecols=['country','date','cases'])\n",
    "cases_by_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_all=pd.read_csv(\"confirmed_cases_china_vs_world.csv\",usecols=[\"is_china\",\"date\",\"cases\"])\n",
    "cases_all = cases_all.rename(columns={'is_china': 'country'})\n",
    "cases_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_china=cases_all.loc[cases_all['country']=='China'].copy()\n",
    "cases_not_china=cases_all.drop(cases_china.index[:])\n",
    "cases_china.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Summarising the total number of confirmed cases by country\n",
    "Obtain the January records for \"cases_by_country\" and \"cases_china\" and summarise cases in China against cases in other countries in a dataframe for this month. Repeat this procedure for February and March. Create a bar plot to compare cases in China with cases in the 5 countries with most cases outside China for January, February and March."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e44e8e14c391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcases_china\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcases_china\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mchina\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcases_china\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchina\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchina\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mchina\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchina\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchina\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "cases_china['date'] = pd.to_datetime(cases_china['date'])\n",
    "china=cases_china.copy()\n",
    "china.insert(0,'month',china['date'].dt.month_name())\n",
    "china=china.groupby(['month','country'])['cases'].sum().reset_index()\n",
    "china.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_by_country['date'] = pd.to_datetime(cases_by_country['date'])\n",
    "countries=cases_by_country.copy()\n",
    "countries.insert(0,'month',countries.date.dt.month_name())\n",
    "countries=countries.groupby(['month','country'])['cases'].sum().reset_index()\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# January cases\n",
    "jan_cases=countries.loc[countries['month']=='January'].sort_values(by='cases',ascending=False)\n",
    "china_jan= china.loc[china['month'] == 'January']\n",
    "jan_cases=pd.concat([china_jan,jan_cases])\n",
    "jan_cases\n",
    "\n",
    "# February cases\n",
    "feb_cases=countries.loc[countries['month']=='February'].sort_values(by='cases',ascending=False)\n",
    "china_feb= china.loc[china['month'] == 'February']\n",
    "feb_cases=pd.concat([china_feb,feb_cases])\n",
    "feb_cases\n",
    "\n",
    "# March cases\n",
    "mar_cases=countries.loc[countries['month']=='March'].sort_values(by='cases',ascending=False)\n",
    "china_mar= china.loc[china['month'] == 'March']\n",
    "mar_cases=pd.concat([china_mar,mar_cases])\n",
    "mar_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: Comparing China's cases with 5 countries with most cumulative cases outside China for January to March\n",
    "countries=countries.groupby(['country'])['cases'].sum().reset_index()\n",
    "countries.sort_values(by='cases',ascending=False).head()\n",
    "\n",
    "# The top 5 countries with the highest cumulative cases from Jan to Mar are Italy, Iran, Spain, Germany and South Korea. Creating a list to filter the monthly dataframes for only these countries.\n",
    "comparing_countries=['China','Italy','Iran','Spain','Germany','Korea, South']\n",
    "top_5_and_china_jan=jan_cases.loc[jan_cases['country'].isin(comparing_countries)]\n",
    "top_5_and_china_feb=feb_cases.loc[feb_cases['country'].isin(comparing_countries)]\n",
    "top_5_and_china_mar=mar_cases.loc[mar_cases['country'].isin(comparing_countries)]\n",
    "top_5_countries_vs_china=pd.concat([top_5_and_china_jan,top_5_and_china_feb, top_5_and_china_mar],ignore_index=True)\n",
    "\n",
    "# Structuring data for graphical analysis\n",
    "top_5_countries_vs_china=top_5_countries_vs_china.set_index(['month','country'])\n",
    "top_5_countries_vs_china=top_5_countries_vs_china.unstack()\n",
    "\n",
    "# Arranging the months in order using categorical indexing\n",
    "top_5_countries_vs_china.index = pd.CategoricalIndex(top_5_countries_vs_china.index, categories=['January','February','March'], ordered=True)\n",
    "top_5_countries_vs_china = top_5_countries_vs_china.sort_index()\n",
    "jan_mar_trend=top_5_countries_vs_china.plot.bar(title='3-month trend of cases in China versus 5 countries with most cases outside China',figsize=(20,10))\n",
    "jan_mar_trend.set_ylabel('Number of Cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Plotting the accumulated cases by date \n",
    "Add a new column called \"acc_cases\" in both \"cases_not_china\" and \"cases_china\" dataframes, which contains the accumulated number of cases by date. Create a time series plot for \"acc_cases\" column in \"cases_not_china\" dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1 for Assumption 1\n",
    "# Assumption 1: Accumulated number of cases by date refers to the total number of daily cases.\n",
    "cases_china['acc_cases'] = cases_china.groupby(['date']).cumsum()\n",
    "cases_not_china['acc_cases']=cases_not_china.groupby(['date']).cumsum()\n",
    "accumulated_cases=cases_not_china.plot(x='date',y='acc_cases',title=\"Accumulated number of cases by date for countries (excluding China)\",figsize=(20,10))\n",
    "accumulated_cases.set_ylabel('Number of Cases')\n",
    "# This graph makes it easier to spot specific dates where the daily cases spiked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2 for Assumption 2\n",
    "# Assumption 2: Accumulated number of cases by date refers to the cumulative number of daily cases.\n",
    "cases_not_china['acc_cases']=cases_not_china['cases'].cumsum()\n",
    "cumulative_cases=cases_not_china.plot(x='date',y='acc_cases',title=\"Cumulative number of cases by date for all countries (excluding China)\",figsize=(20,10))\n",
    "cumulative_cases.set_ylabel('Number of Cases')\n",
    "# This graph helps visualise where the rate of infections rise exponentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4: Analysing across countries \n",
    "When the number of COVID-19 cases became higher than 10,000 in China, what was the number of cases for all other counties in that day? Print the 5 countries with highest number of cases.\n",
    "\n",
    "During the first 5 days that the daily cases in China dropped below 100, what is average number of cases for other countries? Report the top 5 countries with average number of cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the date(s) where daily cases in China were beyond 10,000\n",
    "more_than_10k_china=cases_china.loc[(cases_china['cases']>10000)]\n",
    "more_than_10k_china\n",
    "# China had only one instance between January to March where daily cases exceeded 10,000, which was on the 13th of February 2020, where they had 15,136 new cases.\n",
    "\n",
    "february13_other_countries=cases_by_country.loc[(cases_by_country['date']=='2020-02-13')]\n",
    "february13_other_countries=february13_other_countries.groupby(['country']).sum()\n",
    "february13_other_countries.sort_values('cases',ascending=False).head()\n",
    "# On the date when China had more than 10,000 cases, Singapore had 8 cases, Vietnam had 1 case, US had 1 case and Malaysia had 1 case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the first 5 days that the daily cases in China dropped below 100\n",
    "less_than_100_china=cases_china.loc[(cases_china['cases']<100)]\n",
    "less_than_100_china=less_than_100_china['date'].head(5).tolist()\n",
    "dates_below_100_cases_countries=cases_by_country.loc[cases_by_country['date'].isin(less_than_100_china)]\n",
    "\n",
    "# Assumption: The average number of cases for other countries is the average number of daily cases on the first 5 dates where China had less than 100 daily cases.\n",
    "dates_below_100_cases_countries=dates_below_100_cases_countries.groupby(['country'])['cases'].mean().reset_index()\n",
    "dates_below_100_cases_countries=dates_below_100_cases_countries.sort_values('cases',ascending=False)\n",
    "top_5_highest_average=dates_below_100_cases_countries['country'].head().tolist()\n",
    "print(\"The top 5 countries with the highest average number of cases are {}\".format(top_5_highest_average))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
